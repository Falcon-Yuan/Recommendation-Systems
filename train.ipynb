{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取文件中...\n",
      "数据大小:(5001507, 3)\n",
      "文件读取完成，正在切分数据集...\n",
      "数据集切分完成，耗时 :6185.30339550972 sec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def data_split(data_path, x=0.8, random=False):\n",
    "    print(\"读取文件中...\")\n",
    "    timer = d2l.Timer()\n",
    "    timer.start()\n",
    "    f = open(data_path, 'r')\n",
    "    temp = []\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if line == '':\n",
    "            break\n",
    "        user, num = line.split('|')\n",
    "        for i in range(int(num)):\n",
    "            line = f.readline()\n",
    "            item, rating = line.split('  ')\n",
    "            temp.append([int(user), int(item), int(rating)])\n",
    "\n",
    "    ratings = pd.DataFrame(temp)\n",
    "    ratings.rename(columns={0: 'userId', 1: 'movieId', 2: 'rating'}, inplace=True)\n",
    "    print('数据大小:{}'.format(ratings.shape))\n",
    "    print(\"文件读取完成，正在切分数据集...\")\n",
    "    validation_index = []\n",
    "    for uid in ratings.groupby(\"userId\").any().index:\n",
    "        user_rating_data = ratings.where(ratings[\"userId\"] == uid).dropna()\n",
    "        if random:\n",
    "            index = list(user_rating_data.index)\n",
    "            np.random.shuffle(index)\n",
    "            _index = round(len(user_rating_data) * x)\n",
    "            validation_index += list(index[_index:])\n",
    "        else:\n",
    "            index = round(len(user_rating_data) * x)\n",
    "            validation_index += list(user_rating_data.index.values[index:])\n",
    "\n",
    "    validation_set = ratings.loc[validation_index]\n",
    "    train_set = ratings.drop(validation_index)\n",
    "    timer.stop()\n",
    "    print('数据集切分完成，耗时 :{} sec'.format(timer.sum()))\n",
    "    return train_set, validation_set\n",
    "\n",
    "\n",
    "train_path = 'data-202205/train.txt'\n",
    "test_path = 'data-202205/test.txt'\n",
    "answer_path = 'answer/out.txt'\n",
    "train, validation = data_split(train_path, random=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(predict_results):\n",
    "    metric = d2l.Accumulator(3)\n",
    "    for uid, iid, real_rating, pred_rating in predict_results:\n",
    "        metric.add(1, (pred_rating - real_rating) ** 2, abs(pred_rating - real_rating))\n",
    "    return round(np.sqrt(metric[1] / metric[0]), 4), round(metric[2] / metric[0], 4)\n",
    "\n",
    "\n",
    "def predict_test(file_path, write_path, cf):\n",
    "    f = open(file_path, 'r')\n",
    "    b = open(write_path, 'w')\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if line == '':\n",
    "            break\n",
    "        b.write(line)\n",
    "        user, num = line.split('|')\n",
    "        for i in range(int(num)):\n",
    "            line = f.readline().split('\\n')[0]\n",
    "            rating = cf.predict(int(user), int(line))\n",
    "            b.write(line + '  ' + str(rating) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasSvd:\n",
    "\n",
    "    def __init__(self, dataset, epochs, alpha, hidden, parameter_p, parameter_q, parameter_bu, parameter_bi, columns):\n",
    "        self.dataset = dataset\n",
    "        self.epochs = epochs\n",
    "        self.alpha = alpha\n",
    "        self.hidden = hidden\n",
    "        self.parameter_p = parameter_p\n",
    "        self.parameter_q = parameter_q\n",
    "        self.parameter_bu = parameter_bu\n",
    "        self.parameter_bi = parameter_bi\n",
    "        self.columns = columns\n",
    "        self.users_ratings = dataset.groupby(self.columns[0]).agg([list])[[self.columns[1], self.columns[2]]]\n",
    "        self.items_ratings = dataset.groupby(self.columns[1]).agg([list])[[self.columns[0], self.columns[2]]]\n",
    "        self.global_mean = self.dataset[self.columns[2]].mean()\n",
    "        self.bu = dict(zip(self.users_ratings.index, np.zeros(len(self.users_ratings))))\n",
    "        self.bi = dict(zip(self.items_ratings.index, np.zeros(len(self.items_ratings))))\n",
    "        self.P = dict(zip(\n",
    "            self.users_ratings.index,\n",
    "            np.random.rand(len(self.users_ratings), self.hidden).astype(np.float32)\n",
    "        ))\n",
    "        self.Q = dict(zip(\n",
    "            self.items_ratings.index,\n",
    "            np.random.rand(len(self.items_ratings), self.hidden).astype(np.float32)\n",
    "        ))\n",
    "\n",
    "    def train_bs(self, validation_set):\n",
    "        animator = d2l.Animator(xlabel='epoch', xlim=[1, self.epochs], ylim=[0, 50],\n",
    "                                legend=['train RMSE', 'val'])\n",
    "        timer = d2l.Timer()\n",
    "        for epoch in range(self.epochs):\n",
    "            print('epoch :{}'.format(epoch))\n",
    "            metric = d2l.Accumulator(2)\n",
    "            timer.start()\n",
    "            for i, (uid, iid, real_rating) in enumerate(self.dataset.itertuples(index=False)):\n",
    "                vec_pu = self.P[uid]\n",
    "                vec_qi = self.Q[iid]\n",
    "                error = np.float32(\n",
    "                    real_rating - (self.global_mean + self.bu[uid] + self.bi[iid] + np.dot(vec_pu, vec_qi)))\n",
    "                vec_pu += self.alpha * (error * vec_qi - self.parameter_p * vec_pu)\n",
    "                vec_qi += self.alpha * (error * vec_pu - self.parameter_q * vec_qi)\n",
    "                self.P[uid] = vec_pu\n",
    "                self.Q[iid] = vec_qi\n",
    "                self.bu[uid] += self.alpha * (error - self.parameter_bu * self.bu[uid])\n",
    "                self.bi[iid] += self.alpha * (error - self.parameter_bi * self.bi[iid])\n",
    "                metric.add(1, error ** 2)\n",
    "            timer.stop()\n",
    "            pred_results = self.validate(validation_set)\n",
    "            rmse, mae = evaluate_accuracy(pred_results)\n",
    "            #print(rmse, mae)\n",
    "\n",
    "            animator.add(epoch + 1, (round(np.sqrt(metric[1] / metric[0]), 4), rmse))\n",
    "        print('training time :{}'.format(timer.sum()))\n",
    "        # d2l.plt.show()\n",
    "\n",
    "    def predict(self, uid, iid):\n",
    "        if uid not in self.users_ratings.index or iid not in self.items_ratings.index:\n",
    "            return self.global_mean\n",
    "        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid] + np.dot(self.P[uid], self.Q[iid])\n",
    "        if predict_rating > 100:\n",
    "            predict_rating = 100\n",
    "        if predict_rating < 0:\n",
    "            predict_rating = 0\n",
    "        return predict_rating\n",
    "\n",
    "    def validate(self, validation_set):\n",
    "        for uid, iid, real_rating in validation_set.itertuples(index=False):\n",
    "            try:\n",
    "                pred_rating = self.predict(uid, iid)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            else:\n",
    "                yield uid, iid, real_rating, pred_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineCF:\n",
    "\n",
    "    def __init__(self, dataset, epochs, parameter_bu, parameter_bi, columns):\n",
    "        self.dataset = dataset\n",
    "        self.epochs = epochs\n",
    "        self.parameter_bu = parameter_bu\n",
    "        self.parameter_bi = parameter_bi\n",
    "        self.columns = columns\n",
    "        self.users_ratings = dataset.groupby(self.columns[0]).agg([list])[[self.columns[1], self.columns[2]]]\n",
    "        self.items_ratings = dataset.groupby(self.columns[1]).agg([list])[[self.columns[0], self.columns[2]]]\n",
    "        self.global_mean = self.dataset[self.columns[2]].mean()\n",
    "        self.bu = dict(zip(self.users_ratings.index, np.zeros(len(self.users_ratings))))\n",
    "        self.bi = dict(zip(self.items_ratings.index, np.zeros(len(self.items_ratings))))\n",
    "\n",
    "    def train_bl(self, validation_set):\n",
    "        animator = d2l.Animator(xlabel='epoch', xlim=[1, self.epochs], ylim=[0, 50],\n",
    "                                legend=['train RMSE', 'validation RMSE'])\n",
    "        #timer = d2l.Timer()\n",
    "        # for epoch in range(self.epochs):\n",
    "        #     print('epoch :{}'.format(epoch))\n",
    "        #     metric = d2l.Accumulator(2)\n",
    "        #     timer.start()\n",
    "        #     for i, (uid, iid, real_rating) in enumerate(self.dataset.itertuples(index=False)):\n",
    "        #         error = real_rating - (self.global_mean + self.bu[uid] + self.bi[iid])\n",
    "        #\n",
    "        #         self.bu[uid] += self.alpha * (error - self.parameter * self.bu[uid])\n",
    "        #         self.bi[iid] += self.alpha * (error - self.parameter * self.bi[iid])\n",
    "        #         metric.add(1, error ** 2)\n",
    "        #     timer.stop()\n",
    "        #     pred_results = self.validate(validation_set)\n",
    "        #     rmse, mae = evaluate_accuracy(pred_results)\n",
    "        #     animator.add(epoch + 1, (round(np.sqrt(metric[1] / metric[0]), 4), rmse))\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            for iid, uids, ratings in self.items_ratings.itertuples(index=True):\n",
    "                _sum = 0\n",
    "                for uid, rating in zip(uids, ratings):\n",
    "                    _sum += rating - self.global_mean - self.bu[uid]\n",
    "                self.bi[iid] = _sum / (self.parameter_bi + len(uids))\n",
    "\n",
    "            for uid, iids, ratings in self.users_ratings.itertuples(index=True):\n",
    "                _sum = 0\n",
    "                for iid, rating in zip(iids, ratings):\n",
    "                    _sum += rating - self.global_mean - self.bi[iid]\n",
    "                self.bu[uid] = _sum / (self.parameter_bu + len(iids))\n",
    "\n",
    "            pred_results = self.validate(validation_set)\n",
    "            rmse, mae = evaluate_accuracy(pred_results)\n",
    "            print(rmse, mae)\n",
    "            animator.add(i + 1, (mae, rmse))\n",
    "        d2l.plt.show()\n",
    "\n",
    "    def predict(self, uid, iid):\n",
    "        if iid not in self.items_ratings.index:\n",
    "            return 0\n",
    "        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]\n",
    "        if predict_rating > 100:\n",
    "            predict_rating = 100\n",
    "        if predict_rating < 0:\n",
    "            predict_rating = 0\n",
    "        return predict_rating\n",
    "\n",
    "    def validate(self, validation_set):\n",
    "        for uid, iid, real_rating in validation_set.itertuples(index=False):\n",
    "            try:\n",
    "                pred_rating = self.predict(uid, iid)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            else:\n",
    "                yield uid, iid, real_rating, pred_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BiasSvd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_25068/3441593661.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mbs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mBiasSvd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m15\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.0005\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m80\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'userId'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'movieId'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'rating'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mbs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_bs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalidation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mbl\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mBaselineCF\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'userId'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'movieId'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'rating'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mbl\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_bl\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalidation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'BiasSvd' is not defined"
     ]
    }
   ],
   "source": [
    "    bs = BiasSvd(train, 15, 0.0005, 80, 0.1, 0.1, 0.1, 0.1, ['userId', 'movieId', 'rating'])\n",
    "    bs.train_bs(validation)\n",
    "\n",
    "    bl = BaselineCF(train, 10, 0.3, 0, ['userId', 'movieId', 'rating'])\n",
    "    bl.train_bl(validation)\n",
    "\n",
    "    predict_test(test_path, answer_path, bl, bs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be9ce0e06cc68fc55cd79c70ae492efef7ce425ab7922f50cecddb1a35fc4f86"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}